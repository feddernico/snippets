{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "d0b855f0-f14e-5952-b118-4f8e1cbd572c",
        "openai_ephemeral_user_id": "c8a55c9d-9f4a-50e0-8c13-e7f8bf2dafd2",
        "openai_subdivision1_iso_code": "GB-ENG"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.9",
      "identifier": "legacy",
      "language": "python",
      "language_version": "3.9",
      "name": "python3"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "18d2fd53-5de7-41e7-8e5d-2c81b3b3c409",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "",
      "outputs": []
    },
    {
      "id": "1ca07e74-d949-44e2-bc51-886a707ae560",
      "cell_type": "markdown",
      "source": "# cat2vec\n\n## Aim of the Notebook\nThe main idea of this notebook is to develop a snippet of code to transform categorical features into embeddings using the Gensim Word2Vec library. Below is an initial draft of the methods that will be used:\n\n### Method 1: `apply_w2v`\nThis method takes sentences, a Word2Vec model, and the number of features as input. It returns the average word vectors for each sentence.\n\n```python\ndef apply_w2v(sentences, model, num_features):\n    # ...\n```\n\n### Method 2: `gen_cat2vec_sentences`\nThis method takes a DataFrame and returns a list of sentences, where each sentence is a list of categories.\n\n```python\ndef gen_cat2vec_sentences(df):\n    # ...\n```\n\n### Method 3: `fit_cat2vec_model`\nThis method takes a DataFrame, the number of features, and the window size for the Word2Vec model. It returns a trained Word2Vec model.\n\n```python\ndef fit_cat2vec_model(df, n_cat2vec_features, n_cat2vec_window):\n    # ...\n```\n\nWe will load a toy classification dataset and create an example using a neural network model.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "94db5e96-aab7-4fb4-950c-d948e9e2bc35",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Load the Iris dataset\ndata = load_iris()\ndf = pd.DataFrame(data.data, columns=data.feature_names)\ndf['target'] = data.target\n\n# Split the dataset into training and test sets\ndf_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n\n# Show the first few rows of the training data\ndf_train.head()",
      "outputs": []
    }
  ]
}